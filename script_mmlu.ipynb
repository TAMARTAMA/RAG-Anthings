{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f074be",
   "metadata": {},
   "source": [
    "# script questions to LLM and Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89454050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6e5c1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tamar/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "mmlu_ds = load_dataset(\"cais/mmlu\", \"all\")\n",
    "df = mmlu_ds[\"validation\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bb4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_num_to_letter(num):\n",
    "    mapping = {0: 'a', 1: 'b', 2: 'c', 3: 'd'}\n",
    "    return mapping.get(num, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65c1706",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_times = []\n",
    "correct_Server = []\n",
    "correct_llm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "662d51b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_final_answer(model_response: str,kind:str) -> str | None:\n",
    "    print(f\"{kind}:\\n{model_response}\\n\")\n",
    "    match = re.search(r'Final answer:\\s*([a-dA-D])', model_response)\n",
    "    if match:\n",
    "        return match.group(1).lower()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a396476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_local_llm(question: str):\n",
    "    url = \"http://127.0.0.1:8013/generate\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": question}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status()  \n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"❌ שגיאה בשליחה לשרת: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80807d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to_backend( request_text: str):\n",
    "\n",
    "    url = \"http://localhost:8002/api/message/add\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"userId\": \"demo_user\",\n",
    "        \"request\": request_text\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "        return response.json()  # מחזירה את התגובה כ־dict\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"❌ שגיאה בשליחה לשרת הראשי: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab6c2208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to_add_test(user_id: str, request_text: str):\n",
    "    url = \"http://localhost:8002/api/message/addtest\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"userId\": user_id,\n",
    "        \"request\": request_text\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        return data\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"❌ שגיאה בשליחה לשרת: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee173529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation(sample_df):\n",
    "    response_times = []\n",
    "    correct_flags_s = []\n",
    "    correct_mlm_flags = []\n",
    "    for index, row in sample_df.iterrows():\n",
    "        choices = row[\"choices\"].tolist() if not isinstance(row[\"choices\"], list) else row[\"choices\"]\n",
    "        gold_letter = convert_num_to_letter(int(row[\"answer\"]))\n",
    "        \n",
    "        prompt_M = f\"\"\"\n",
    "    Question: {row['question']}\n",
    "    Answers:\n",
    "    a. {choices[0]}\n",
    "    b. {choices[1]}\n",
    "    c. {choices[2]}\n",
    "    d. {choices[3]}\n",
    "\n",
    "    Answer the question by selecting one option from each of the answers. \n",
    "    Briefly explain your reasoning, and then give a final answer of the letter of the selected answer in this exact format:\n",
    "    Final answer: <letter>\n",
    "    \"\"\"\n",
    "        \n",
    "        prompt_S =f\"\"\"Which of the following answers answers the question?\n",
    "    Question: {row['question']}\n",
    "    Answers:\n",
    "    a. {choices[0]}\n",
    "    b. {choices[1]}\n",
    "    c. {choices[2]}\n",
    "    d. {choices[3]}\n",
    "\n",
    "    Answer the in this exact format:\n",
    "    Final answer: <letter>\n",
    "    \"\"\"\n",
    "\n",
    "        try:\n",
    "            start_time = time.time()\n",
    "            response = send_message_to_backend(prompt_S)['answer']\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            response_times.append(duration)\n",
    "            model_output = ask_local_llm(prompt_M)['text']\n",
    "\n",
    "            pred_s = extract_final_answer(response,\"Server\")\n",
    "            pred_m = extract_final_answer(model_output,\"LLM\")\n",
    "            if pred_s:\n",
    "                is_correct = (pred_s == gold_letter)\n",
    "            else:\n",
    "                pred_s = \"?\"\n",
    "                is_correct = False\n",
    "            correct_flags_s.append(is_correct)\n",
    "            if pred_m:\n",
    "                is_correct = (pred_m == gold_letter)\n",
    "            else:\n",
    "                pred_s = \"?\"\n",
    "                is_correct = False\n",
    "            correct_mlm_flags.append(is_correct)\n",
    "            print(f\"[{index}] \\nServer: {pred_s} \\nLLM:{pred_m} \\n---excpected: {gold_letter} in {duration:.2f}s  \\n\")\n",
    "\n",
    "            # print(f\"Subject:{row['subject']}\\n Question: {row['question']} \\n Choices:a. {choices[0]}\\nb. {choices[1]}\\nc. {choices[2]}\\nd. {choices[3]}\\n\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[{index}] ❌ error: {e}\")\n",
    "    return response_times, correct_flags_s , correct_mlm_flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a539434d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def summarize_and_plot(response_times, correct_flags,correct_mlm_flags):\n",
    "\n",
    "    accuracy = 100 * sum(correct_flags) / len(correct_flags)\n",
    "    avg_time = np.mean(response_times)\n",
    "    median_time = np.median(response_times)\n",
    "    std_time = np.std(response_times)\n",
    "\n",
    "    print(\"\\n--- Summary ---\")\n",
    "    print(f\"Total questions: {len(response_times)}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "    print(\"\\n----Model LLM---\")\n",
    "    accuracy_mlm = 100 * sum(correct_mlm_flags) / len(correct_mlm_flags)\n",
    "    print(f\"Accuracy: {accuracy_mlm:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6e2717dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['abstract_algebra', 'anatomy', 'astronomy', 'business_ethics',\n",
       "       'clinical_knowledge', 'college_biology', 'college_chemistry',\n",
       "       'college_computer_science', 'college_mathematics',\n",
       "       'college_medicine', 'college_physics', 'computer_security',\n",
       "       'conceptual_physics', 'econometrics', 'electrical_engineering',\n",
       "       'elementary_mathematics', 'formal_logic', 'global_facts',\n",
       "       'high_school_biology', 'high_school_chemistry',\n",
       "       'high_school_computer_science', 'high_school_european_history',\n",
       "       'high_school_geography', 'high_school_government_and_politics',\n",
       "       'high_school_macroeconomics', 'high_school_mathematics',\n",
       "       'high_school_microeconomics', 'high_school_physics',\n",
       "       'high_school_psychology', 'high_school_statistics',\n",
       "       'high_school_us_history', 'high_school_world_history',\n",
       "       'human_aging', 'human_sexuality', 'international_law',\n",
       "       'jurisprudence', 'logical_fallacies', 'machine_learning',\n",
       "       'management', 'marketing', 'medical_genetics', 'miscellaneous',\n",
       "       'moral_disputes', 'moral_scenarios', 'nutrition', 'philosophy',\n",
       "       'prehistory', 'professional_accounting', 'professional_law',\n",
       "       'professional_medicine', 'professional_psychology',\n",
       "       'public_relations', 'security_studies', 'sociology',\n",
       "       'us_foreign_policy', 'virology', 'world_religions'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = df['subject'].unique()\n",
    "subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c09e1ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df[df['subject'] == 'high_school_computer_science'].sample(n=2, random_state=42)\n",
    "# response_times, correct_flags ,correct_flags_LLM = run_evaluation(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a65997b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_process_asking(row: str):\n",
    "    choices = row[\"choices\"].tolist() if not isinstance(row[\"choices\"], list) else row[\"choices\"]\n",
    "    gold_letter = convert_num_to_letter(int(row[\"answer\"]))\n",
    "    promt = f\"\"\"\n",
    "    Question: {row['question']}\n",
    "    Answers:\n",
    "    a. {choices[0]}\n",
    "    b. {choices[1]}\n",
    "    c. {choices[2]}\n",
    "    d. {choices[3]}\n",
    "\n",
    "    \"\"\"\n",
    "    output = send_message_to_add_test(\"demo_user\",promt)\n",
    "    print(\"Gold answer:\",gold_letter)\n",
    "    print(\"Q:\",row['question'])\n",
    "    print(\"Choices:\")\n",
    "    for c in choices:\n",
    "        print(c)\n",
    "    print(json.dumps(output, indent=2, ensure_ascii=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "52ca5b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_llm(row: str):\n",
    "    choices = row[\"choices\"].tolist() if not isinstance(row[\"choices\"], list) else row[\"choices\"]\n",
    "    gold_letter = convert_num_to_letter(int(row[\"answer\"]))\n",
    "    promt = f\"\"\"Which of the following answers answers the question?\n",
    "    Question: {row['question']}\n",
    "    Answers:\n",
    "    a. {choices[0]}\n",
    "    b. {choices[1]}\n",
    "    c. {choices[2]}\n",
    "    d. {choices[3]}\n",
    "\n",
    "    Respond only answer with the letter (a, b, c, d) of the correct answer. \n",
    "    Do not write words or explanations - only the appropriate letter.\n",
    "    \"\"\"\n",
    "    output = ask_local_llm(promt)\n",
    "    print(\"Gold answer:\",gold_letter)\n",
    "    print(\"Q:\",row['question'])\n",
    "    print(\"Choices:\")\n",
    "    for c in choices:\n",
    "        print(c)\n",
    "    print(json.dumps(output, indent=2, ensure_ascii=False))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68cfb0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    Which of the following best describes a Web se...\n",
       "subject                          high_school_computer_science\n",
       "choices     [A computer system that delivers Web pages to ...\n",
       "answer                                                      0\n",
       "Name: 345, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3dce51",
   "metadata": {},
   "source": [
    "תשובה נכונה"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16a9de11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ שגיאה בשליחה לשרת: 500 Server Error: Internal Server Error for url: http://localhost:8002/api/message/addtest\n",
      "Gold answer: a\n",
      "Q: Which of the following best describes a Web server?\n",
      "Choices:\n",
      "A computer system that delivers Web pages to clients\n",
      "A computer system that determines the shortest path between two computers over the Internet\n",
      "A computer system running software that provides a user-friendly interface for creating Web pages\n",
      "A computer system that translates domain names to IP addresses\n",
      "null\n"
     ]
    }
   ],
   "source": [
    "get_response_process_asking(sample_df.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb5a2db",
   "metadata": {},
   "source": [
    "תשובה שגויה מהמודל הקטן"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "973070f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold answer: b\n",
      "Q: Which of the following guidelines is applicable to initialization of the weight vector in a fully connected neural network.\n",
      "Choices:\n",
      "Should not set it to zero since otherwise it will cause overfitting\n",
      "Should not set it to zero since otherwise (stochastic) gradient descent will explore a very small space\n",
      "Should set it to zero since otherwise it causes a bias\n",
      "Should set it to zero in order to preserve symmetry across all neurons\n",
      "{\n",
      "  \"text\": \"a\",\n",
      "  \"tokens\": 3,\n",
      "  \"duration_s\": 0.36277174949645996\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "get_response_llm(sample_df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e63831a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Summary ---\n",
      "Total questions: 2\n",
      "Accuracy: 0.00%\n",
      "\n",
      "----Model LLM---\n",
      "Accuracy: 0.00%\n"
     ]
    }
   ],
   "source": [
    "summarize_and_plot(response_times, correct_flags,correct_flags_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce4411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df[df['subject'] == 'machine_learning'].sample(n=2, random_state=42)\n",
    "response_times, correct_flags ,correct_flags_LLM = run_evaluation(sample_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
